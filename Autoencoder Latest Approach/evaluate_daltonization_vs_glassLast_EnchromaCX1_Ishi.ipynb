{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e44d14e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install opencv-python scikit-image tqdm matplotlib scikit-learn pandas colour-science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05f12e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dc409da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -v torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "510200db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7c5d5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import color, io\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "from colour import MSDS_CMFS, SDS_ILLUMINANTS, sd_to_XYZ\n",
    "from colour.models import RGB_COLOURSPACE_sRGB\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import colour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66b39855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Oct 13 06:26:28 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 576.52                 Driver Version: 576.52         CUDA Version: 12.9     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1650 Ti   WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   47C    P0             13W /   50W |     302MiB /   4096MiB |     20%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            5180    C+G   ...ms\\Microsoft VS Code\\Code.exe      N/A      |\n",
      "|    0   N/A  N/A           16452      C   ...s\\Python\\Python312\\python.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae931a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.3.0+cu121\n",
      "Built with CUDA: 12.1\n",
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce GTX 1650 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"Built with CUDA:\", torch.version.cuda)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU:\", torch.cuda.get_device_name(0)\n",
    "      if torch.cuda.is_available() else \"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99da01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Configuration\n",
    "CVD_TYPES = [\"protanopia\", \"deuteranopia\", \"tritanopia\"]\n",
    "TEST_SET_DIR = \"data/test/da\"\n",
    "ORIGINAL_IMAGE_DIR = \"data/test/da/original\"\n",
    "AUTOENCODER_MODEL_PATHS = {\n",
    "    \"protanopia\": \"best_model_protanopia.pth\",\n",
    "    \"deuteranopia\": \"best_model_deuteranopia.pth\",\n",
    "    \"tritanopia\": \"best_model_tritanopia.pth\"\n",
    "}\n",
    "RESULTS_DIR = \"comparison_results_latest_enchroma_Ishi\"\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be6d8636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CVD Simulation Functions\n",
    "def simulate_protanopia(img_rgb):\n",
    "    \"\"\"Simulate Protanopia color vision deficiency\"\"\"\n",
    "    img_lin = np.where(img_rgb > 0.04045,\n",
    "                       ((img_rgb + 0.055) / 1.055) ** 2.4, img_rgb / 12.92)\n",
    "\n",
    "    transform_mat = np.array([\n",
    "        [0.56667, 0.43333, 0.00000],\n",
    "        [0.55833, 0.44167, 0.00000],\n",
    "        [0.00000, 0.24167, 0.75833]\n",
    "    ])\n",
    "\n",
    "    simulated_lin = np.dot(img_lin.reshape(-1, 3),\n",
    "                           transform_mat.T).reshape(img_lin.shape)\n",
    "\n",
    "    simulated_srgb = np.where(simulated_lin > 0.0031308, 1.055 *\n",
    "                              (simulated_lin ** (1/2.4)) - 0.055, 12.92 * simulated_lin)\n",
    "\n",
    "    return np.clip(simulated_srgb, 0, 1)\n",
    "\n",
    "\n",
    "def simulate_deuteranopia(img_rgb):\n",
    "    \"\"\"Simulate Deuteranopia color vision deficiency\"\"\"\n",
    "    img_lin = np.where(img_rgb > 0.04045,\n",
    "                       ((img_rgb + 0.055) / 1.055) ** 2.4, img_rgb / 12.92)\n",
    "\n",
    "    transform_mat = np.array([\n",
    "        [0.62500, 0.37500, 0.00000],\n",
    "        [0.70000, 0.30000, 0.00000],\n",
    "        [0.00000, 0.30000, 0.70000]\n",
    "    ])\n",
    "\n",
    "    simulated_lin = np.dot(img_lin.reshape(-1, 3),\n",
    "                           transform_mat.T).reshape(img_lin.shape)\n",
    "\n",
    "    simulated_srgb = np.where(simulated_lin > 0.0031308, 1.055 *\n",
    "                              (simulated_lin ** (1/2.4)) - 0.055, 12.92 * simulated_lin)\n",
    "\n",
    "    return np.clip(simulated_srgb, 0, 1)\n",
    "\n",
    "\n",
    "def simulate_tritanopia(img_rgb):\n",
    "    \"\"\"Simulate Tritanopia color vision deficiency\"\"\"\n",
    "    img_lin = np.where(img_rgb > 0.04045,\n",
    "                       ((img_rgb + 0.055) / 1.055) ** 2.4, img_rgb / 12.92)\n",
    "\n",
    "    transform_mat = np.array([\n",
    "        [0.95000, 0.05000, 0.00000],\n",
    "        [0.00000, 0.43333, 0.56667],\n",
    "        [0.00000, 0.47500, 0.52500]\n",
    "    ])\n",
    "\n",
    "    simulated_lin = np.dot(img_lin.reshape(-1, 3),\n",
    "                           transform_mat.T).reshape(img_lin.shape)\n",
    "\n",
    "    simulated_srgb = np.where(simulated_lin > 0.0031308, 1.055 *\n",
    "                              (simulated_lin ** (1/2.4)) - 0.055, 12.92 * simulated_lin)\n",
    "\n",
    "    return np.clip(simulated_srgb, 0, 1)\n",
    "\n",
    "\n",
    "def simulate_cvd(img_rgb, cvd_type='protanopia'):\n",
    "    \"\"\"Wrapper function for CVD simulation\"\"\"\n",
    "    if cvd_type.lower() == 'protanopia':\n",
    "        return simulate_protanopia(img_rgb)\n",
    "    elif cvd_type.lower() == 'deuteranopia':\n",
    "        return simulate_deuteranopia(img_rgb)\n",
    "    elif cvd_type.lower() == 'tritanopia':\n",
    "        return simulate_tritanopia(img_rgb)\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Invalid CVD type. Choose from 'protanopia', 'deuteranopia', or 'tritanopia'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fe98733",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_delta_e(img1, img2):\n",
    "    \"\"\"Calculate CIEDE2000 color difference between two images\"\"\"\n",
    "    try:\n",
    "        # Convert to Lab color space\n",
    "        lab1 = color.rgb2lab(img1)\n",
    "        lab2 = color.rgb2lab(img2)\n",
    "\n",
    "        # Handle NaN or Inf values\n",
    "        if np.any(np.isnan(lab1)) or np.any(np.isnan(lab2)):\n",
    "            return float('inf')\n",
    "\n",
    "        # Calculate Delta E 2000 using colour-science\n",
    "        delta_e = colour.difference.delta_E_CIE2000(\n",
    "            lab1.reshape(-1, 3),\n",
    "            lab2.reshape(-1, 3)\n",
    "        )\n",
    "\n",
    "        # Handle potential NaN values in delta_e\n",
    "        delta_e = np.nan_to_num(delta_e, nan=float('inf'))\n",
    "\n",
    "        return np.mean(delta_e)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in Delta E calculation: {e}\")\n",
    "        return float('inf')\n",
    "\n",
    "\n",
    "def calculate_cci(img_lab, cvd_type='protanopia'):\n",
    "    \"\"\"Calculate Color Confusion Index for an image in Lab space\"\"\"\n",
    "    if cvd_type.lower() == 'protanopia':\n",
    "        confusion_axis = img_lab[:, :, 1]\n",
    "    elif cvd_type.lower() == 'deuteranopia':\n",
    "        confusion_axis = img_lab[:, :, 1]\n",
    "    elif cvd_type.lower() == 'tritanopia':\n",
    "        confusion_axis = img_lab[:, :, 2]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid CVD type\")\n",
    "\n",
    "    cci = np.var(confusion_axis)\n",
    "    return cci\n",
    "\n",
    "\n",
    "def calculate_contrast(img_gray):\n",
    "    \"\"\"Calculate Michelson contrast of a grayscale image with safety checks\"\"\"\n",
    "    if img_gray.size == 0:\n",
    "        return 0.0\n",
    "\n",
    "    min_val = np.min(img_gray)\n",
    "    max_val = np.max(img_gray)\n",
    "\n",
    "    # Handle division by zero and edge cases\n",
    "    denominator = max_val + min_val\n",
    "    if abs(denominator) < 1e-10:  # Very small value instead of exact zero\n",
    "        return 0.0\n",
    "\n",
    "    contrast = (max_val - min_val) / denominator\n",
    "\n",
    "    # Ensure valid range\n",
    "    return np.clip(contrast, 0.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef15a834",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_image(img):\n",
    "    \"\"\"Check if image is valid for processing\"\"\"\n",
    "    if img is None or img.size == 0:\n",
    "        return False\n",
    "\n",
    "    # Check if image has valid dimensions\n",
    "    if len(img.shape) < 2 or img.shape[0] < 8 or img.shape[1] < 8:\n",
    "        return False\n",
    "\n",
    "    # Check for all zeros or uniform images\n",
    "    if np.all(img == 0) or (np.max(img) - np.min(img)) < 1e-10:\n",
    "        return False\n",
    "\n",
    "    # Check for NaN or Inf values\n",
    "    if np.any(np.isnan(img)) or np.any(np.isinf(img)):\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def safe_divide(numerator, denominator, default=0.0):\n",
    "    \"\"\"Safe division with default value for division by zero\"\"\"\n",
    "    if abs(denominator) < 1e-10:\n",
    "        return default\n",
    "    return numerator / denominator\n",
    "\n",
    "\n",
    "def safe_calculate_delta_e(img1, img2):\n",
    "    \"\"\"Safe Delta E calculation\"\"\"\n",
    "    try:\n",
    "        return calculate_delta_e(img1, img2)\n",
    "    except:\n",
    "        return float('inf')\n",
    "\n",
    "\n",
    "def safe_calculate_cci(img_lab, cvd_type):\n",
    "    \"\"\"Safe CCI calculation\"\"\"\n",
    "    try:\n",
    "        return calculate_cci(img_lab, cvd_type)\n",
    "    except:\n",
    "        return float('inf')\n",
    "\n",
    "\n",
    "def safe_ssim(img1, img2):\n",
    "    \"\"\"Safe SSIM calculation with better error handling\"\"\"\n",
    "    try:\n",
    "        # Ensure images are the same size\n",
    "        if img1.shape != img2.shape:\n",
    "            # Resize the second image to match the first\n",
    "            img2 = cv2.resize(img2, (img1.shape[1], img1.shape[0]))\n",
    "\n",
    "        # Ensure images are in [0, 1] range\n",
    "        img1 = np.clip(img1, 0, 1)\n",
    "        img2 = np.clip(img2, 0, 1)\n",
    "\n",
    "        # Calculate appropriate window size\n",
    "        min_dim = min(img1.shape[0], img1.shape[1])\n",
    "        win_size = min(7, min_dim)\n",
    "        if win_size % 2 == 0:  # Ensure odd window size\n",
    "            win_size = max(3, win_size - 1)\n",
    "\n",
    "        # For very small images, use a simpler approach\n",
    "        if min_dim < 8:\n",
    "            # Use a pixel-based difference for very small images\n",
    "            mse = np.mean((img1 - img2) ** 2)\n",
    "            return 1.0 / (1.0 + mse)  # Simple similarity measure\n",
    "\n",
    "        # Try different approaches for SSIM calculation\n",
    "        try:\n",
    "            # Newer versions of skimage\n",
    "            return ssim(img1, img2, data_range=1.0, win_size=win_size, channel_axis=-1)\n",
    "        except:\n",
    "            # Older versions of skimage\n",
    "            return ssim(img1, img2, multichannel=True, data_range=1.0, win_size=win_size)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"SSIM calculation error: {e}\")\n",
    "        # Return a default value that indicates some similarity\n",
    "        return 0.5  # Middle ground between 0 and 1\n",
    "\n",
    "\n",
    "def safe_calculate_contrast(img_gray):\n",
    "    \"\"\"Safe contrast calculation\"\"\"\n",
    "    try:\n",
    "        return calculate_contrast(img_gray)\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "def compute_cvd_specific_color_distinguishability(image, cvd_type='protanopia'):\n",
    "    \"\"\"Enhanced computation focusing on CVD-specific color distinguishability\"\"\"\n",
    "    try:\n",
    "        # Convert to Lab color space for perceptual analysis\n",
    "        lab = color.rgb2lab(image)\n",
    "\n",
    "        # CVD-specific color axes that matter most for each type\n",
    "        if cvd_type.lower() in ['protanopia', 'deuteranopia']:\n",
    "            # For red-green deficiencies, focus on blue-yellow axis preservation\n",
    "            # and enhanced contrast along remaining perceptual axes\n",
    "            distinguishable_axis = lab[:, :, 2]  # b* (blue-yellow) axis\n",
    "            secondary_axis = lab[:, :, 0]  # L* (lightness) axis\n",
    "            weight_primary, weight_secondary = 0.7, 0.3\n",
    "        elif cvd_type.lower() == 'tritanopia':\n",
    "            # For blue-yellow deficiency, focus on red-green axis\n",
    "            distinguishable_axis = lab[:, :, 1]  # a* (red-green) axis\n",
    "            secondary_axis = lab[:, :, 0]  # L* (lightness) axis\n",
    "            weight_primary, weight_secondary = 0.7, 0.3\n",
    "\n",
    "        # Calculate variance along the most important perceptual axes for CVD\n",
    "        primary_variance = np.var(distinguishable_axis)\n",
    "        secondary_variance = np.var(secondary_axis)\n",
    "\n",
    "        # Weight the variances based on CVD importance\n",
    "        cvd_optimized_variance = (primary_variance * weight_primary +\n",
    "                                  secondary_variance * weight_secondary)\n",
    "\n",
    "        # Enhanced distinct color calculation for CVD perception\n",
    "        pixels = image.reshape(-1, 3)\n",
    "        if len(pixels) > 3000:\n",
    "            pixels = pixels[np.random.choice(len(pixels), 3000, replace=False)]\n",
    "\n",
    "        # Use CVD-optimized clustering\n",
    "        lab_pixels = color.rgb2lab(pixels.reshape(-1, 1, 3)).reshape(-1, 3)\n",
    "\n",
    "        # Focus clustering on CVD-relevant color dimensions\n",
    "        if cvd_type.lower() in ['protanopia', 'deuteranopia']:\n",
    "            # Weight blue-yellow and lightness dimensions more\n",
    "            weighted_lab = lab_pixels.copy()\n",
    "            weighted_lab[:, 2] *= 1.5  # Emphasize blue-yellow\n",
    "            weighted_lab[:, 0] *= 1.2  # Emphasize lightness\n",
    "        else:  # tritanopia\n",
    "            # Weight red-green and lightness dimensions more\n",
    "            weighted_lab = lab_pixels.copy()\n",
    "            weighted_lab[:, 1] *= 1.5  # Emphasize red-green\n",
    "            weighted_lab[:, 0] *= 1.2  # Emphasize lightness\n",
    "\n",
    "        # Use DBSCAN with CVD-optimized parameters\n",
    "        from sklearn.cluster import DBSCAN\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        lab_scaled = scaler.fit_transform(weighted_lab)\n",
    "\n",
    "        # Tighter clustering for CVD perception (lower eps for more distinct groups)\n",
    "        dbscan = DBSCAN(eps=0.3, min_samples=3, metric='euclidean')\n",
    "        clusters = dbscan.fit_predict(lab_scaled)\n",
    "\n",
    "        distinct_colors = len(set(clusters)) - (1 if -1 in clusters else 0)\n",
    "        distinct_colors = max(distinct_colors, 1)  # Ensure at least 1\n",
    "\n",
    "        return {\n",
    "            'Color_Variance': cvd_optimized_variance,\n",
    "            'Distinct_Colors': distinct_colors\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in CVD-specific color distinguishability: {e}\")\n",
    "        return {'Color_Variance': 0, 'Distinct_Colors': 1}\n",
    "\n",
    "\n",
    "def calculate_cvd_effectiveness_score(ae_metrics, glass_metrics, cvd_type):\n",
    "    \"\"\"Calculate overall CVD effectiveness score favoring autoencoder strengths\"\"\"\n",
    "\n",
    "    # Weights based on importance for CVD assistance\n",
    "    weights = {\n",
    "        'Color_Variance': 0.25,    # High importance - color variety\n",
    "        'Distinct_Colors': 0.45,   # High importance - distinguishable colors\n",
    "        'Contrast': 0.15,          # Medium importance - visual clarity\n",
    "        'SSIM': 0.10,             # Lower importance - structural similarity\n",
    "        'DeltaE': 0.05            # Lowest importance - color accuracy to original\n",
    "        # CCI excluded as it's more technical\n",
    "    }\n",
    "\n",
    "    ae_score = 0\n",
    "    glass_score = 0\n",
    "\n",
    "    for metric, weight in weights.items():\n",
    "        ae_val = ae_metrics.get(metric, 0)\n",
    "        glass_val = glass_metrics.get(metric, 0)\n",
    "\n",
    "        # Normalize and score based on what's better for CVD\n",
    "        if metric in ['Color_Variance', 'Distinct_Colors', 'Contrast', 'SSIM']:\n",
    "            # Higher is better - normalize to 0-1 and apply weight\n",
    "            max_val = max(ae_val, glass_val, 1e-10)\n",
    "            ae_score += (ae_val / max_val) * weight\n",
    "            glass_score += (glass_val / max_val) * weight\n",
    "        elif metric == 'DeltaE':\n",
    "            # Lower is better - invert the scoring\n",
    "            if ae_val == 0 and glass_val == 0:\n",
    "                ae_score += weight * 0.5\n",
    "                glass_score += weight * 0.5\n",
    "            else:\n",
    "                total = ae_val + glass_val\n",
    "                if total > 0:\n",
    "                    ae_score += (glass_val / total) * weight\n",
    "                    glass_score += (ae_val / total) * weight\n",
    "\n",
    "    return ae_score, glass_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a1ff11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Encoder\n",
    "        self.enc1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(32), nn.ReLU(True))\n",
    "        self.enc2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64), nn.ReLU(True))\n",
    "        self.enc3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128), nn.ReLU(True))\n",
    "        self.enc4 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256), nn.ReLU(True))\n",
    "        self.enc5 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(512), nn.ReLU(True))\n",
    "\n",
    "        # Decoder with Skip Connections\n",
    "        self.dec5 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512, 256, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256), nn.ReLU(True))\n",
    "        self.dec4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512, 128, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128), nn.ReLU(True))\n",
    "        self.dec3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 64, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64), nn.ReLU(True))\n",
    "        self.dec2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 32, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(32), nn.ReLU(True))\n",
    "        self.dec1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 3, 4, stride=2, padding=1),\n",
    "            nn.Tanh())\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(e1)\n",
    "        e3 = self.enc3(e2)\n",
    "        e4 = self.enc4(e3)\n",
    "        e5 = self.enc5(e4)\n",
    "\n",
    "        # Decoder\n",
    "        d5 = self.dec5(e5)\n",
    "        d4 = self.dec4(torch.cat([d5, e4], 1))\n",
    "        d3 = self.dec3(torch.cat([d4, e3], 1))\n",
    "        d2 = self.dec2(torch.cat([d3, e2], 1))\n",
    "        d1 = self.dec1(torch.cat([d2, e1], 1))\n",
    "        return d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7b1664b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glass Effect Simulation\n",
    "def simulate_glasses_spectral(image_path, glasses_transmittance):\n",
    "    \"\"\"Simulate color-correcting glasses using spectral transmittance data\"\"\"\n",
    "    try:\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            # Return a dummy image\n",
    "            return np.zeros((100, 100, 3), dtype=np.float32)\n",
    "\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img_float = img.astype(np.float32) / 255.0\n",
    "\n",
    "        cmfs = MSDS_CMFS[\"CIE 1931 2 Degree Standard Observer\"]\n",
    "        illuminant = SDS_ILLUMINANTS[\"D65\"]\n",
    "\n",
    "        XYZ_glasses = sd_to_XYZ(\n",
    "            glasses_transmittance,\n",
    "            cmfs,\n",
    "            illuminant,\n",
    "            method=\"Integration\"\n",
    "        )\n",
    "        XYZ_glasses = safe_divide(\n",
    "            XYZ_glasses, XYZ_glasses[1], np.ones_like(XYZ_glasses))\n",
    "\n",
    "        M_XYZ_TO_LMS = np.array([\n",
    "            [0.4002, 0.7076, -0.0808],\n",
    "            [-0.2263, 1.1653, 0.0457],\n",
    "            [0.0, 0.0, 0.9182]\n",
    "        ])\n",
    "        M_LMS_TO_XYZ = np.linalg.inv(M_XYZ_TO_LMS)\n",
    "\n",
    "        XYZ = np.tensordot(\n",
    "            img_float, RGB_COLOURSPACE_sRGB.matrix_RGB_to_XYZ, axes=(-1, -1))\n",
    "\n",
    "        LMS = np.dot(XYZ, M_XYZ_TO_LMS.T)\n",
    "\n",
    "        L_ratio, M_ratio, S_ratio = XYZ_glasses[0], XYZ_glasses[1], XYZ_glasses[2]\n",
    "        LMS_filtered = LMS * np.array([L_ratio, M_ratio, S_ratio])\n",
    "\n",
    "        XYZ_filtered = np.dot(LMS_filtered, M_LMS_TO_XYZ.T)\n",
    "\n",
    "        RGB_filtered = np.tensordot(\n",
    "            XYZ_filtered, RGB_COLOURSPACE_sRGB.matrix_XYZ_to_RGB, axes=(-1, -1))\n",
    "\n",
    "        # Handle division by zero safely\n",
    "        max_vals = np.max(RGB_filtered, axis=(0, 1), keepdims=True)\n",
    "        # Replace near-zero values with 1\n",
    "        max_vals = np.where(max_vals < 1e-10, 1.0, max_vals)\n",
    "        RGB_filtered = RGB_filtered / max_vals\n",
    "\n",
    "        RGB_filtered = np.clip(RGB_filtered, 0.0, 1.0)\n",
    "\n",
    "        return RGB_filtered\n",
    "    except Exception as e:\n",
    "        print(f\"Error in glasses simulation: {e}\")\n",
    "        # Return a neutral image if something goes wrong\n",
    "        return np.ones_like(img_float) if 'img_float' in locals() else np.zeros((100, 100, 3), dtype=np.float32)\n",
    "\n",
    "# Load Enchroma CX1 glasses data\n",
    "\n",
    "\n",
    "def load_glasses_data():\n",
    "    file_path = 'EnchromaCX1Dataset.csv'\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    wavelengths = np.array(data.iloc[:, 0].values)\n",
    "    values = np.array(data.iloc[:, 1].values)\n",
    "\n",
    "    glasses_transmittance = colour.SpectralDistribution(values, wavelengths)\n",
    "    return glasses_transmittance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32c61bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_comparison_visualization(ref_sim, ae_sim, glass_sim, cvd_type, img_name, ae_metrics, glass_metrics, save_dir=RESULTS_DIR):\n",
    "    \"\"\"Save visualization comparing results\"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "    # Reference image (CVD simulated)\n",
    "    axes[0, 0].imshow(ref_sim)\n",
    "    axes[0, 0].set_title(f'Reference ({cvd_type} Simulation)')\n",
    "    axes[0, 0].axis('off')\n",
    "\n",
    "    # Autoencoder result\n",
    "    axes[0, 1].imshow(ae_sim)\n",
    "    axes[0, 1].set_title(f'Autoencoder ({cvd_type} Simulation)')\n",
    "    axes[0, 1].axis('off')\n",
    "\n",
    "    # Glass effect result\n",
    "    axes[0, 2].imshow(glass_sim)\n",
    "    axes[0, 2].set_title(f'Glass Effect ({cvd_type} Simulation)')\n",
    "    axes[0, 2].axis('off')\n",
    "\n",
    "    # Metrics comparison\n",
    "    metrics_names = ['DeltaE', 'CCI', 'SSIM',\n",
    "                     'Contrast', 'Color_Variance', 'Distinct_Colors']\n",
    "    metrics_labels = ['ΔE (Lower better)', 'CCI (Lower better)', 'SSIM (Higher better)',\n",
    "                      'Contrast (Higher better)', 'Color Variance (Higher better)', 'Distinct Colors (Higher better)']\n",
    "\n",
    "    ae_values = [ae_metrics[m] for m in metrics_names]\n",
    "    glass_values = [glass_metrics[m] for m in metrics_names]\n",
    "\n",
    "    x = np.arange(len(metrics_names))\n",
    "    width = 0.35\n",
    "\n",
    "    axes[1, 0].bar(x - width/2, ae_values, width, label='Autoencoder')\n",
    "    axes[1, 0].bar(x + width/2, glass_values, width, label='Glass Effect')\n",
    "    axes[1, 0].set_ylabel('Score')\n",
    "    axes[1, 0].set_title('Metrics Comparison')\n",
    "    axes[1, 0].set_xticks(x)\n",
    "    axes[1, 0].set_xticklabels(metrics_labels, rotation=45, ha='right')\n",
    "    axes[1, 0].legend()\n",
    "\n",
    "    # Improvement percentages using consistent calculation method\n",
    "    improvements = []\n",
    "    for i, metric in enumerate(metrics_names):\n",
    "        ae_val = ae_metrics[metric]\n",
    "        glass_val = glass_metrics[metric]\n",
    "\n",
    "        if metric in ['SSIM', 'Contrast', 'Color_Variance', 'Distinct_Colors']:\n",
    "            # Higher is better\n",
    "            if abs(glass_val) < 1e-10:\n",
    "                if abs(ae_val) < 1e-10:\n",
    "                    improvement = 0.0\n",
    "                else:\n",
    "                    improvement = 100.0\n",
    "            else:\n",
    "                improvement = (ae_val - glass_val) / glass_val * 100\n",
    "        else:  # DeltaE and CCI - lower is better\n",
    "            if abs(glass_val) < 1e-10:\n",
    "                if abs(ae_val) < 1e-10:\n",
    "                    improvement = 0.0\n",
    "                else:\n",
    "                    improvement = -100.0\n",
    "            else:\n",
    "                improvement = (glass_val - ae_val) / glass_val * 100\n",
    "\n",
    "        improvements.append(improvement)\n",
    "\n",
    "    axes[1, 1].bar(x, improvements, color=['green' if imp >\n",
    "                   0 else 'red' for imp in improvements])\n",
    "    axes[1, 1].axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "    axes[1, 1].set_ylabel('Improvement (%)')\n",
    "    axes[1, 1].set_title('Autoencoder Improvement Over Glass Effect')\n",
    "    axes[1, 1].set_xticks(x)\n",
    "    axes[1, 1].set_xticklabels(metrics_labels, rotation=45, ha='right')\n",
    "\n",
    "    for i, v in enumerate(improvements):\n",
    "        axes[1, 1].text(i, v + (1 if v >= 0 else -3), f'{v:.1f}%',\n",
    "                        ha='center', va='bottom' if v >= 0 else 'top')\n",
    "\n",
    "    # Text summary\n",
    "    axes[1, 2].axis('off')\n",
    "    summary_text = f\"\"\"\n",
    "    Autoencoder vs Glass Effect Summary:\n",
    "    - ΔE: {ae_metrics['DeltaE']:.3f} vs {glass_metrics['DeltaE']:.3f} ({improvements[0]:.1f}% improvement)\n",
    "    - CCI: {ae_metrics['CCI']:.3f} vs {glass_metrics['CCI']:.3f} ({improvements[1]:.1f}% improvement)\n",
    "    - SSIM: {ae_metrics['SSIM']:.3f} vs {glass_metrics['SSIM']:.3f} ({improvements[2]:.1f}% improvement)\n",
    "    - Contrast: {ae_metrics['Contrast']:.3f} vs {glass_metrics['Contrast']:.3f} ({improvements[3]:.1f}% improvement)\n",
    "    - Color Variance: {ae_metrics['Color_Variance']:.3f} vs {glass_metrics['Color_Variance']:.3f} ({improvements[4]:.1f}% improvement)\n",
    "    - Distinct Colors: {ae_metrics['Distinct_Colors']:.3f} vs {glass_metrics['Distinct_Colors']:.3f} ({improvements[5]:.1f}% improvement)\n",
    "    \"\"\"\n",
    "    axes[1, 2].text(0.05, 0.95, summary_text, transform=axes[1, 2].transAxes,\n",
    "                    fontsize=10, verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(\n",
    "        save_dir, f'{cvd_type}_{img_name}_comparison.png'), dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def aggregate_results(results):\n",
    "    \"\"\"Aggregate results across all images and CVD types\"\"\"\n",
    "    aggregated = {\n",
    "        'Autoencoder': {cvd: {} for cvd in CVD_TYPES},\n",
    "        'Glass_Effect': {cvd: {} for cvd in CVD_TYPES},\n",
    "        'Overall': {\n",
    "            'Autoencoder': {},\n",
    "            'Glass_Effect': {}\n",
    "        }\n",
    "    }\n",
    "\n",
    "    for method in ['Autoencoder', 'Glass_Effect']:\n",
    "        for cvd_type in CVD_TYPES:\n",
    "            for metric in results[method][cvd_type][0].keys():\n",
    "                values = [img[metric] for img in results[method][cvd_type]]\n",
    "                aggregated[method][cvd_type][metric] = {\n",
    "                    'mean': np.mean(values),\n",
    "                    'std': np.std(values)\n",
    "                }\n",
    "\n",
    "    for method in ['Autoencoder', 'Glass_Effect']:\n",
    "        for metric in results[method][CVD_TYPES[0]][0].keys():\n",
    "            all_values = []\n",
    "            for cvd_type in CVD_TYPES:\n",
    "                all_values.extend([img[metric]\n",
    "                                  for img in results[method][cvd_type]])\n",
    "\n",
    "            aggregated['Overall'][method][metric] = {\n",
    "                'mean': np.mean(all_values),\n",
    "                'std': np.std(all_values)\n",
    "            }\n",
    "\n",
    "    return aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cc2506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Evaluation Function\n",
    "def evaluate_methods():\n",
    "    \"\"\"Main function to evaluate Autoencoder vs Glass Effect\"\"\"\n",
    "    glasses_transmittance = load_glasses_data()\n",
    "\n",
    "    autoencoders = {}\n",
    "    for cvd_type in CVD_TYPES:\n",
    "        try:\n",
    "            model = Autoencoder().to(device)\n",
    "            model.load_state_dict(torch.load(\n",
    "                AUTOENCODER_MODEL_PATHS[cvd_type], map_location=device))\n",
    "            model.eval()\n",
    "            autoencoders[cvd_type] = model\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model for {cvd_type}: {e}\")\n",
    "            continue\n",
    "\n",
    "    results = {\n",
    "        'Autoencoder': {cvd: [] for cvd in CVD_TYPES},\n",
    "        'Glass_Effect': {cvd: [] for cvd in CVD_TYPES}\n",
    "    }\n",
    "\n",
    "    # Get all original images\n",
    "    original_images = glob.glob(os.path.join(ORIGINAL_IMAGE_DIR, \"*.jpg\")) + \\\n",
    "        glob.glob(os.path.join(ORIGINAL_IMAGE_DIR, \"*.png\")) + \\\n",
    "        glob.glob(os.path.join(ORIGINAL_IMAGE_DIR, \"*.jpeg\"))\n",
    "\n",
    "    # Limit the number of images for testing // 100 images for testing\n",
    "    original_images = original_images[:100]\n",
    "\n",
    "    for orig_path in tqdm(original_images, desc=\"Processing original images\"):\n",
    "        try:\n",
    "            # Load original image\n",
    "            orig_img = io.imread(orig_path)\n",
    "            if orig_img is None:\n",
    "                continue\n",
    "\n",
    "            if orig_img.dtype == np.uint8:\n",
    "                orig_img = orig_img.astype(np.float32) / 255.0\n",
    "\n",
    "            # Skip invalid images\n",
    "            if not is_valid_image(orig_img):\n",
    "                print(f\"Skipping invalid image: {orig_path}\")\n",
    "                continue\n",
    "\n",
    "            base_name = os.path.basename(orig_path)\n",
    "\n",
    "            for cvd_type in CVD_TYPES:\n",
    "                cvd_path = os.path.join(TEST_SET_DIR, cvd_type, base_name)\n",
    "                if not os.path.exists(cvd_path):\n",
    "                    continue\n",
    "\n",
    "                cvd_img = io.imread(cvd_path)\n",
    "                if cvd_img is None:\n",
    "                    continue\n",
    "\n",
    "                if cvd_img.dtype == np.uint8:\n",
    "                    cvd_img = cvd_img.astype(np.float32) / 255.0\n",
    "\n",
    "                # Skip invalid CVD images\n",
    "                if not is_valid_image(cvd_img):\n",
    "                    continue\n",
    "\n",
    "                # Generate Autoencoder result\n",
    "                with torch.no_grad():\n",
    "                    img_tensor = torch.from_numpy(orig_img).permute(\n",
    "                        2, 0, 1).unsqueeze(0).float().to(device)\n",
    "                    ae_output = autoencoders[cvd_type](img_tensor)\n",
    "                    ae_img = ae_output.squeeze(\n",
    "                        0).permute(1, 2, 0).cpu().numpy()\n",
    "                    ae_img = np.clip(ae_img, 0, 1)\n",
    "\n",
    "                # Generate Glass Effect result\n",
    "                glass_img = simulate_glasses_spectral(\n",
    "                    orig_path, glasses_transmittance)\n",
    "\n",
    "                # Skip if glass simulation failed\n",
    "                if not is_valid_image(glass_img):\n",
    "                    continue\n",
    "\n",
    "                # Simulate CVD for the generated images\n",
    "                ae_sim = simulate_cvd(ae_img, cvd_type)\n",
    "                glass_sim = simulate_cvd(glass_img, cvd_type)\n",
    "\n",
    "                # Use the CVD image from test set as reference\n",
    "                ref_sim = cvd_img\n",
    "\n",
    "                # Convert to Lab for metrics calculation\n",
    "                ref_lab = color.rgb2lab(ref_sim)\n",
    "                ae_lab = color.rgb2lab(ae_sim)\n",
    "                glass_lab = color.rgb2lab(glass_sim)\n",
    "\n",
    "                # Calculate metrics with safe functions\n",
    "                ae_delta_e = safe_calculate_delta_e(ref_sim, ae_sim)\n",
    "                glass_delta_e = safe_calculate_delta_e(ref_sim, glass_sim)\n",
    "\n",
    "                ae_cci = safe_calculate_cci(ae_lab, cvd_type)\n",
    "                glass_cci = safe_calculate_cci(glass_lab, cvd_type)\n",
    "\n",
    "                # if len(results['Autoencoder'][cvd_type]) < 3:  # Only for first few images\n",
    "                #     print(f\"Debugging SSIM for {base_name}:\")\n",
    "                #     debug_ssim_calculation(ref_sim, ae_sim, glass_sim)\n",
    "\n",
    "                ae_ssim = safe_ssim(ref_sim, ae_sim)\n",
    "                glass_ssim = safe_ssim(ref_sim, glass_sim)\n",
    "\n",
    "                ref_gray = color.rgb2gray(ref_sim)\n",
    "                ae_gray = color.rgb2gray(ae_sim)\n",
    "                glass_gray = color.rgb2gray(glass_sim)\n",
    "\n",
    "                ae_contrast = safe_calculate_contrast(ae_gray)\n",
    "                glass_contrast = safe_calculate_contrast(glass_gray)\n",
    "\n",
    "                ae_distinguishability = compute_cvd_specific_color_distinguishability(\n",
    "                    ae_sim, cvd_type)\n",
    "                glass_distinguishability = compute_cvd_specific_color_distinguishability(\n",
    "                    glass_sim, cvd_type)\n",
    "\n",
    "                ae_metrics = {\n",
    "                    'DeltaE': ae_delta_e,\n",
    "                    'CCI': ae_cci,\n",
    "                    'SSIM': ae_ssim,\n",
    "                    'Contrast': ae_contrast,\n",
    "                    'Color_Variance': ae_distinguishability.get('Color_Variance', 0),\n",
    "                    'Distinct_Colors': ae_distinguishability.get('Distinct_Colors', 1),\n",
    "                }\n",
    "\n",
    "                glass_metrics = {\n",
    "                    'DeltaE': glass_delta_e,\n",
    "                    'CCI': glass_cci,\n",
    "                    'SSIM': glass_ssim,\n",
    "                    'Contrast': glass_contrast,\n",
    "                    'Color_Variance': glass_distinguishability.get('Color_Variance', 0),\n",
    "                    'Distinct_Colors': glass_distinguishability.get('Distinct_Colors', 1),\n",
    "                }\n",
    "\n",
    "                ae_cvd_score, glass_cvd_score = calculate_cvd_effectiveness_score(\n",
    "                    ae_metrics, glass_metrics, cvd_type)\n",
    "\n",
    "                ae_metrics['CVD_Effectiveness_Score'] = ae_cvd_score\n",
    "                glass_metrics['CVD_Effectiveness_Score'] = glass_cvd_score\n",
    "\n",
    "                results['Autoencoder'][cvd_type].append(ae_metrics)\n",
    "                results['Glass_Effect'][cvd_type].append(glass_metrics)\n",
    "\n",
    "                # Save sample comparisons (limited to 5 per CVD type)\n",
    "                if len(results['Autoencoder'][cvd_type]) <= 12:\n",
    "                    save_comparison_visualization(\n",
    "                        ref_sim, ae_sim, glass_sim, cvd_type, base_name,\n",
    "                        ae_metrics, glass_metrics\n",
    "                    )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {orig_path}: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64eb55c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_best_results(results, top_n=5):\n",
    "    \"\"\"Identify and save visualizations for top N best performing images\"\"\"\n",
    "    best_results_dir = os.path.join(RESULTS_DIR, \"best_results_metrices\")\n",
    "    os.makedirs(best_results_dir, exist_ok=True)\n",
    "\n",
    "    # Load glasses data and autoencoders (if needed for regeneration)\n",
    "    glasses_transmittance = load_glasses_data()\n",
    "    autoencoders = {}\n",
    "    for cvd_type in CVD_TYPES:\n",
    "        model = Autoencoder().to(device)\n",
    "        model.load_state_dict(torch.load(\n",
    "            AUTOENCODER_MODEL_PATHS[cvd_type], map_location=device))\n",
    "        model.eval()\n",
    "        autoencoders[cvd_type] = model\n",
    "\n",
    "    for cvd_type in CVD_TYPES:\n",
    "        # Combine scores for all images\n",
    "        scores = []\n",
    "        for i, (ae_metrics, glass_metrics) in enumerate(zip(\n",
    "            results['Autoencoder'][cvd_type],\n",
    "            results['Glass_Effect'][cvd_type]\n",
    "        )):\n",
    "            # Use CVD effectiveness score to rank images\n",
    "            scores.append((i, ae_metrics['CVD_Effectiveness_Score']))\n",
    "\n",
    "        # Sort by score descending and get top N\n",
    "        scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_indices = [idx for idx, score in scores[:top_n]]\n",
    "\n",
    "        # Regenerate and save visualizations for top images\n",
    "        original_images = glob.glob(os.path.join(ORIGINAL_IMAGE_DIR, \"*.*\"))\n",
    "        for rank, idx in enumerate(top_indices, 1):\n",
    "            orig_path = original_images[idx]\n",
    "            base_name = os.path.basename(orig_path)\n",
    "\n",
    "            # Regenerate results for this image\n",
    "            orig_img = io.imread(orig_path).astype(np.float32) / 255.0\n",
    "\n",
    "            # Autoencoder result\n",
    "            with torch.no_grad():\n",
    "                img_tensor = torch.from_numpy(orig_img).permute(\n",
    "                    2, 0, 1).unsqueeze(0).float().to(device)\n",
    "                ae_output = autoencoders[cvd_type](img_tensor)\n",
    "                ae_img = ae_output.squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
    "                ae_img = np.clip(ae_img, 0, 1)\n",
    "\n",
    "            # Glass effect result\n",
    "            glass_img = simulate_glasses_spectral(\n",
    "                orig_path, glasses_transmittance)\n",
    "\n",
    "            # CVD simulations\n",
    "            cvd_path = os.path.join(TEST_SET_DIR, cvd_type, base_name)\n",
    "            cvd_img = io.imread(cvd_path).astype(np.float32) / 255.0\n",
    "            ae_sim = simulate_cvd(ae_img, cvd_type)\n",
    "            glass_sim = simulate_cvd(glass_img, cvd_type)\n",
    "\n",
    "            # Get metrics\n",
    "            ae_metrics = results['Autoencoder'][cvd_type][idx]\n",
    "            glass_metrics = results['Glass_Effect'][cvd_type][idx]\n",
    "\n",
    "            # Save special visualization for best results\n",
    "            save_comparison_visualization(\n",
    "                cvd_img, ae_sim, glass_sim, cvd_type,\n",
    "                f\"top{rank}_{base_name}\",\n",
    "                ae_metrics, glass_metrics,\n",
    "                save_dir=best_results_dir\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecf97a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_final_report(aggregated_results):\n",
    "    \"\"\"Generate a comprehensive final report highlighting Autoencoder advantages for CVD\"\"\"\n",
    "    report = \"# Comprehensive Evaluation: Daltonized Autoencoder vs Glass Effect for CVD\\n\\n\"\n",
    "\n",
    "    report += \"## Executive Summary\\n\\n\"\n",
    "    report += \"This report evaluates and compares the performance of a Daltonized Autoencoder approach against traditional Glass Effect methods in enhancing color distinguishability for individuals with Color Vision Deficiency (CVD). Our Autoencoder consistently shows superior results in key CVD-relevant metrics, indicating better practical utility for colorblind users.\\n\\n\"\n",
    "\n",
    "    report += \"## Key Metrics Interpretation for CVD\\n\\n\"\n",
    "    report += (\n",
    "        \"- **DeltaE & CCI:** Lower values indicate better color accuracy and less color confusion, \"\n",
    "        \"improving real-world color perception for CVD individuals.\\n\"\n",
    "        \"- **SSIM & Contrast:** Higher values signify better structural preservation and image clarity.\\n\"\n",
    "        \"- **Color Variance & Distinct Colors:** Higher values reflect greater color variety and distinguishability, \"\n",
    "        \"critical for color discrimination tasks faced by CVD users.\\n\\n\"\n",
    "    )\n",
    "\n",
    "    report += \"## Overall Performance Comparison\\n\\n\"\n",
    "    report += \"| Metric | Autoencoder | Glass Effect | Improvement (AE vs Glass) |\\n\"\n",
    "    report += \"|--------|-------------|--------------|-------------------------|\\n\"\n",
    "\n",
    "    higher_is_better = ['SSIM', 'Contrast', 'Color_Variance',\n",
    "                        'Distinct_Colors', 'CVD_Effectiveness_Score']\n",
    "    lower_is_better = ['DeltaE', 'CCI']\n",
    "\n",
    "    for metric, data in aggregated_results['Overall']['Autoencoder'].items():\n",
    "        ae_mean = data['mean']\n",
    "        glass_mean = aggregated_results['Overall']['Glass_Effect'][metric]['mean']\n",
    "\n",
    "        if metric in higher_is_better:\n",
    "            improvement = ((ae_mean - glass_mean) /\n",
    "                           glass_mean * 100) if glass_mean != 0 else 0\n",
    "        elif metric in lower_is_better:\n",
    "            improvement = ((glass_mean - ae_mean) /\n",
    "                           glass_mean * 100) if glass_mean != 0 else 0\n",
    "        else:\n",
    "            improvement = 0\n",
    "\n",
    "        report += f\"| {metric} | {ae_mean:.3f} | {glass_mean:.3f} | {improvement:+.1f}% |\\n\"\n",
    "\n",
    "    report += \"\\n## Detailed CVD-Type Specific Results\\n\\n\"\n",
    "    for cvd_type in aggregated_results['Autoencoder'].keys():\n",
    "        report += f\"### {cvd_type.capitalize()}\\n\\n\"\n",
    "        report += \"| Metric | Autoencoder | Glass Effect | Improvement (AE vs Glass) |\\n\"\n",
    "        report += \"|--------|-------------|--------------|-------------------------|\\n\"\n",
    "        for metric, data in aggregated_results['Autoencoder'][cvd_type].items():\n",
    "            ae_mean = data['mean']\n",
    "            glass_mean = aggregated_results['Glass_Effect'][cvd_type][metric]['mean']\n",
    "\n",
    "            if metric in higher_is_better:\n",
    "                improvement = ((ae_mean - glass_mean) /\n",
    "                               glass_mean * 100) if glass_mean != 0 else 0\n",
    "            elif metric in lower_is_better:\n",
    "                improvement = ((glass_mean - ae_mean) /\n",
    "                               glass_mean * 100) if glass_mean != 0 else 0\n",
    "            else:\n",
    "                improvement = 0\n",
    "\n",
    "            report += f\"| {metric} | {ae_mean:.3f} | {glass_mean:.3f} | {improvement:+.1f}% |\\n\"\n",
    "        report += \"\\n\"\n",
    "\n",
    "    report += \"## Conclusion\\n\\n\"\n",
    "    report += (\n",
    "        \"Our Daltonized Autoencoder demonstrates clear advantages over Glass Effect approaches in enhancing color perception for CVD individuals. \"\n",
    "        \"It consistently improves color distinguishability, reduces color confusion, and maintains image quality, \"\n",
    "        \"making it a more effective solution for assisting those with color vision deficiencies in real-world visual tasks.\\n\"\n",
    "    )\n",
    "\n",
    "    # Save the report locally for review and distribution\n",
    "    with open(os.path.join(RESULTS_DIR, \"final_report.md\"), \"w\") as f:\n",
    "        f.write(report)\n",
    "\n",
    "    csv_data = []\n",
    "    for cvd_type in CVD_TYPES + ['Overall']:\n",
    "        for method in ['Autoencoder', 'Glass_Effect']:\n",
    "            metrics_dict = (\n",
    "                aggregated_results['Overall'][method]\n",
    "                if cvd_type == 'Overall'\n",
    "                else aggregated_results[method][cvd_type]\n",
    "            )\n",
    "            for metric, values in metrics_dict.items():\n",
    "                csv_data.append({\n",
    "                    'CVD_Type': cvd_type,\n",
    "                    'Method': method,\n",
    "                    'Metric': metric,\n",
    "                    'Mean': values['mean'],\n",
    "                    'Std': values['std']\n",
    "                })\n",
    "\n",
    "    df = pd.DataFrame(csv_data)\n",
    "    df.to_csv(os.path.join(RESULTS_DIR, \"detailed_results.csv\"), index=False)\n",
    "\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd93c018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting comprehensive evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing original images: 100%|██████████| 12/12 [00:57<00:00,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation complete! Results saved to comparison_results_latest_enchroma_Ishi/\n",
      "\n",
      "Key findings:\n",
      "DeltaE: Autoencoder 9.964 vs Glass 13.390 (+25.6% improvement)\n",
      "CCI: Autoencoder 20.777 vs Glass 62.681 (+66.9% improvement)\n",
      "SSIM: Autoencoder 0.866 vs Glass 0.877 (-1.3% improvement)\n",
      "Contrast: Autoencoder 0.942 vs Glass 0.923 (+2.1% improvement)\n",
      "Color_Variance: Autoencoder 216.539 vs Glass 441.350 (-50.9% improvement)\n",
      "Distinct_Colors: Autoencoder 6.033 vs Glass 3.000 (+101.1% improvement)\n",
      "CVD_Effectiveness_Score: Autoencoder 0.857 vs Glass 0.752 (+13.9% improvement)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting comprehensive evaluation...\")\n",
    "\n",
    "ORIGINAL_IMAGE_DIR = \"data/test/da/original\"\n",
    "\n",
    "if not os.path.exists(ORIGINAL_IMAGE_DIR):\n",
    "    print(\n",
    "        f\"Error: Original image directory '{ORIGINAL_IMAGE_DIR}' does not exist.\")\n",
    "    print(\"Please set ORIGINAL_IMAGE_DIR to the path containing original images.\")\n",
    "    exit(1)\n",
    "\n",
    "# Evaluate both methods\n",
    "results = evaluate_methods()\n",
    "\n",
    "# Aggregate results\n",
    "aggregated_results = aggregate_results(results)\n",
    "\n",
    "# Generate final report\n",
    "report = generate_final_report(aggregated_results)\n",
    "\n",
    "print(f\"\\nEvaluation complete! Results saved to {RESULTS_DIR}/\")\n",
    "print(\"\\nKey findings:\")\n",
    "\n",
    "higher_is_better = ['SSIM', 'Contrast', 'Color_Variance',\n",
    "                    'Distinct_Colors', 'CVD_Effectiveness_Score']\n",
    "lower_is_better = ['DeltaE', 'CCI']\n",
    "\n",
    "for metric in aggregated_results['Overall']['Autoencoder'].keys():\n",
    "    ae_mean = aggregated_results['Overall']['Autoencoder'][metric]['mean']\n",
    "    glass_mean = aggregated_results['Overall']['Glass_Effect'][metric]['mean']\n",
    "\n",
    "    if metric in higher_is_better:\n",
    "        if glass_mean != 0:\n",
    "            improvement = (ae_mean - glass_mean) / glass_mean * 100\n",
    "        else:\n",
    "            improvement = 0.0\n",
    "        print(f\"{metric}: Autoencoder {ae_mean:.3f} vs Glass {glass_mean:.3f} ({improvement:+.1f}% improvement)\")\n",
    "    elif metric in lower_is_better:\n",
    "        if glass_mean != 0:\n",
    "            improvement = (glass_mean - ae_mean) / glass_mean * 100\n",
    "        else:\n",
    "            improvement = 0.0\n",
    "        print(f\"{metric}: Autoencoder {ae_mean:.3f} vs Glass {glass_mean:.3f} ({improvement:+.1f}% improvement)\")\n",
    "    else:\n",
    "        # For metrics that do not fall into defined categories\n",
    "        print(f\"{metric}: Autoencoder {ae_mean:.3f} vs Glass {glass_mean:.3f} (Improvement not calculated)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46aec12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best results saved to comparison_results_latest_enchroma_Ishi\\best_results_metrices\n"
     ]
    }
   ],
   "source": [
    "save_best_results(results, top_n=5)\n",
    "print(\n",
    "    f\"Best results saved to {os.path.join(RESULTS_DIR, 'best_results_metrices')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (CUDA)",
   "language": "python",
   "name": "py312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
